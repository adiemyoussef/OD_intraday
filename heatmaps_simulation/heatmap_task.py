import base64
import time
import pandas as pd
import pytz
from kaleido.scopes.plotly import PlotlyScope
from matplotlib import pyplot as plt
from cupy_numba.main import compute_all
import argparse
import os
from datetime import datetime, timedelta
import numpy as np
from heatmaps_simulation.intraday_plot import *
from config.config import *
import logging
from utilities.db_utils import *
import requests
from datetime import datetime
import io
from prefect import task, flow, get_run_logger
from plotly.io import to_image
from PIL import Image
import plotly.io as pio

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Create a console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# Create a formatter and set it for the handler
file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(file_formatter)

# Add the handler to the logger
logger.addHandler(console_handler)


db = DatabaseUtilities(DB_HOST, int(DB_PORT), DB_USER, DB_PASSWORD, DB_NAME)
db.connect()
print(f'{db.get_status()}')

stage_pg_data = PostGreData(
    host=POSGRE_STAGE_DB_HOST,
    port=POSGRE_STAGE_DB_PORT,
    user=POSGRE_STAGE_DB_USER,
    password=POSGRE_STAGE_DB_PASSWORD,
    database=POSGRE_STAGE_DB_NAME
)
print(f'{stage_pg_data.get_status()}')



DEV_CHANNEL ='https://discord.com/api/webhooks/1274040299735486464/Tp8OSd-aX6ry1y3sxV-hmSy0J3UDhQeyXQbeLD1T9XF5zL4N5kJBBiQFFgKXNF9315xJ'



def send_to_discord(webhook_url, image, content=None, title=None, description=None, fields=None, footer_text=None):
    """
    Sends a message to Discord with an embedded message first, followed by an image in a separate message.

    :param webhook_url: Discord webhook URL
    :param image: Image as a file path, bytes, or file-like object
    :param content: Optional content text
    :param title: Title for the embed
    :param description: Description for the embed
    :param fields: Fields for the embed
    :param footer_text: Footer text for the embed
    :return: Status code of the second request
    """
    prefect_logger = get_run_logger()

    # First Request: Send the embedded message
    embed = {
        "title": title or "Heatmap Update",
        "description": description or "Here's the latest gamma heatmap.",
        "color": 3447003,  # A nice blue color
        "fields": fields or [],
        "footer": {"text": footer_text or "Generated by OptionsDepth Inc."},
        "timestamp": datetime.utcnow().isoformat()
    }

    payload = {
        "embeds": [embed],
        "content": content or ""
    }

    response = requests.post(webhook_url, json=payload)
    if response.status_code == 200 or response.status_code == 204:
        prefect_logger.info("Embedded message sent successfully to Discord!")
    else:
        prefect_logger.error(f"Failed to send Embedded message. Status code: {response.status_code}")
        prefect_logger.error(f"Response content: {response.content}")
        return response.status_code

    # Prepare the image for sending
    if isinstance(image, str):  # If image is a file path
        with open(image, 'rb') as img_file:
            image_data = img_file.read()
    elif isinstance(image, bytes):  # If image is already in bytes
        image_data = image
    elif hasattr(image, 'read'):  # If image is a file-like object
        image_data = image.read()
    else:
        prefect_logger.error("Unsupported image type")
        return 400

    # Convert image to PNG if it's not already
    try:
        img = Image.open(io.BytesIO(image_data))
        with io.BytesIO() as output:
            img.save(output, format='PNG')
            image_data = output.getvalue()
    except Exception as e:
        prefect_logger.error(f"Error processing image: {e}")
        return 400

    # Second Request: Send the image
    files = {
        'file': ('image.png', image_data, 'image/png')
    }

    response = requests.post(webhook_url, files=files)
    if response.status_code == 200 or response.status_code == 204:
        prefect_logger.info("Image sent successfully to Discord!")
    else:
        prefect_logger.error(f"Failed to send Image. Status code: {response.status_code}")
        prefect_logger.error(f"Response content: {response.content}")

    return response.status_code
def build_unpivot(df, effective_datetime, minima, maxima, ticker='SPX'):

    prefect_logger = get_run_logger()
    df_unpivot = df.reset_index().melt(id_vars=['index'], var_name='price', value_name='value')
    df_unpivot['minima'] = minima.reset_index().melt(id_vars=['index'], var_name='price', value_name='value').value
    df_unpivot['maxima'] = maxima.reset_index().melt(id_vars=['index'], var_name='price', value_name='value').value
    df_unpivot.rename(columns={'index': 'sim_datetime'}, inplace=True)

    effective_date = df_unpivot['sim_datetime'].iloc[0].date()

    df_unpivot.insert(3, 'effective_datetime', effective_datetime)
    df_unpivot.insert(2, 'effective_date', effective_date)
    df_unpivot.insert(1, 'ticker', ticker)

    df_unpivot = df_unpivot.replace({np.nan: None})
    prefect_logger.info(f'{df_unpivot.head()}')

    return df_unpivot

def time_to_secs(x):
    return x.total_seconds() / 86400

def array_tte(sim_times, expiration):
    array_tte = []
    for time in sim_times:
        tte = expiration - time
        array_tte.append(time_to_secs(tte))

    return array_tte

def simulation_times(start_time: datetime):
    """
    Generate an array of simulation times. The last value will be 15:59, replacing 16:00.

    :param start_time: Must be a datetime object, e.g., datetime(2023, 1, 11, 8, 30)
    :return: List of simulation times.
    """
    close_time = start_time.replace(second=0, microsecond=0, minute=0, hour=16)
    #close_time = start_time.replace(second=0, microsecond=0, minute=30, hour=9)
    incoming_sim_times = []

    while start_time <= close_time:
        incoming_sim_times.append(start_time)
        start_time += timedelta(minutes=HEATMAP_TIME_STEPS)

    # Replace the last time (16:00) with 15:59
    if incoming_sim_times[-1].time() == datetime(1, 1, 1, 16, 0).time():
        incoming_sim_times[-1] = incoming_sim_times[-1].replace(minute=59, hour=15)
    # else:
    #     incoming_sim_times.append(incoming_sim_times[-1].replace(minute=59, hour=15))

    return incoming_sim_times

def price_matrix(latest_price, steps, interval):
    """
    :param latest_price     : center price of the interval
    :param steps            : increment to take between each price point
    :param interval         : % up and down from the latest price (2% must be input as 0.02)
    :return:  returns a list of prices
    """
    latest_active_spx_price = latest_price
    pepe = 5 * round(latest_active_spx_price / 5)

    simulation_steps = steps
    lower_bound = round((1 - interval) * pepe)
    upper_bound = round((1 + interval) * pepe)

    lower_end = np.arange(pepe, lower_bound, -simulation_steps).tolist()
    upper_end = np.arange(pepe, upper_bound, +simulation_steps).tolist()
    list_prices = np.unique(np.sort(np.concatenate((lower_end, upper_end), dtype=float)))

    return list_prices

def book_to_list(book:pd.DataFrame, sim_times):

    """
    receives the book from the db, and structures it to include times to expiration
    :param book: the book from the db
    :return:
    """
    #breakpoint()
    book['expiration_date'] = pd.to_datetime(book['expiration_date'])
    book['expiration_date'] = book.apply(
        lambda row: row['expiration_date'].replace(hour=16, minute=0) if row['option_symbol'] == 'SPXW' else (
            row['expiration_date'].replace(hour=9, minute=15) if row['option_symbol'] == 'SPX' else row[
                'expiration_date']), axis=1)
    book['tte'] = book.apply(lambda row: array_tte(sim_times, row["expiration_date"]), axis=1)

    result = book[['call_put_flag', 'strike_price', 'iv', 'tte', 'mm_posn']].copy()
    result['iv'].replace({'0': 0.00000000001, 0: 0.00000000001}, inplace = True)

    return result.values.tolist()

def resample_and_convert_timezone(df:pd.DataFrame, datetime_column='effective_datetime', resample_interval='5T',
                                  target_timezone='US/Eastern'):
    """
    Resample a dataframe with 1-minute OHLCV data to a specified interval and convert timezone.

    Parameters:
    df (pandas.DataFrame): Input dataframe with OHLCV data
    datetime_column (str): Name of the datetime column (default: 'effective_datetime')
    resample_interval (str): Pandas resample rule (default: '5T' for 5 minutes)
    timezone (str): Timezone to convert to (default: 'US/Eastern')

    Returns:
    pandas.DataFrame: Resampled dataframe with converted timezone
    """

    # Ensure the datetime column is in the correct format
    df[datetime_column] = pd.to_datetime(df[datetime_column])

    # Set the datetime column as index
    df = df.set_index(datetime_column)

    # Check if the index is timezone-aware
    if df.index.tzinfo is None:
        # If timezone-naive, assume it's UTC and localize
        df.index = df.index.tz_localize('UTC')

    # Convert to target timezone
    target_tz = pytz.timezone(target_timezone)
    df.index = df.index.tz_convert(target_tz)

    # Resample to the specified interval
    df_resampled = df.resample(resample_interval).agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
    })

    # Reset index to make datetime a column again
    df_resampled.reset_index(inplace=True)

    # Remove timezone information after conversion if needed
    df_resampled[datetime_column] = df_resampled[datetime_column].dt.tz_localize(None)

    return df_resampled

@task(name= "Generate heatmap")
def generate_heatmaps(sim_times: list, prices: list, deltas:np.ndarray, trade_date:datetime.date, hour_start:datetime.date):
    prefect_logger = get_run_logger()

    prefect_logger.info("Generating heatmap results")
    simtime_number = []
    for (i, time) in enumerate(sim_times):
        simtime_number.append(i)


    charm = np.gradient(deltas, axis=1, edge_order=2)
    gamma = np.gradient(deltas, axis=0, edge_order=2)
    gamma_der = np.gradient(gamma, axis=0, edge_order=2)
    gamma_2der = np.gradient(gamma_der, axis=0, edge_order=2)


    df_charm = pd.DataFrame(charm.transpose(), columns=prices)
    df_gamma = pd.DataFrame(gamma.transpose(), columns=prices)
    df_gamma_der = pd.DataFrame(gamma_der.transpose(), columns=prices)
    df_gamma_2der = pd.DataFrame(gamma_2der.transpose(), columns=prices)

    hm_time_index = []
    for i in range(0, len(df_charm), 1):
        hour_string = str(hour_start)
        begin_time = datetime.strptime(hour_string, '%H:%M:%S')
        t = (begin_time + timedelta(minutes=i * 5)).time()
        full_date_time = datetime.combine(trade_date, t)
        hm_time_index.append(full_date_time)

    # Format
    df_charm.index = hm_time_index
    df_gamma.index = hm_time_index
    df_gamma_der.index = hm_time_index
    df_gamma_2der.index = hm_time_index


    return df_charm, df_gamma, df_gamma_der, df_gamma_2der


@task(name= "Compute heatmap")
def compute_heatmap(args, type: str, df_book: pd.DataFrame, start_time: datetime, price: float, steps: float, range: float):
    prefect_logger = get_run_logger()
    num_processors = os.cpu_count()
    prefect_logger.info(f"Number of processors available:{num_processors}")
    args.proc = num_processors
    args.mode = type

    prefect_logger.info(f"df_book in compute_heatmap:{df_book.head()}")
    #TODO: Friday AM TEST
    df_book['iv'] = df_book['iv'].astype(float)

    prices = price_matrix(price, steps, range).tolist()

    sim_times = simulation_times(start_time)

    book = book_to_list(df_book,sim_times)

    delta_array = compute_all(args,book,prices)

    df_charm, df_gamma, df_gammader, df_gamma2der = generate_heatmaps(sim_times, prices, delta_array, start_time.date(),
                                                                      start_time.time())

    mask_maxima = df_gamma2der > 0
    mask_minima = df_gamma2der < 0

    maxima_df = df_gammader.copy()
    maxima_df[mask_maxima] = np.nan

    minima_df = df_gammader.copy()
    minima_df[mask_minima] = np.nan


    return df_charm, df_gamma, minima_df, maxima_df

@task(name= "Fetch Data")
def fetch_data_from_db(query):
    return db.execute_query(query)

@task(name= 'Plot and send chart')
def plot_and_send_chart(df_gamma, minima_df, maxima_df, effective_datetime, spx_candlesticks=None):
    prefect_logger = get_run_logger()

    # Convert effective_datetime from string to datetime object if necessary
    if isinstance(effective_datetime, str):
        effective_datetime = datetime.strptime(effective_datetime, '%Y-%m-%d %H:%M:%S')

    prefect_logger.info(f"Plotting gamma chart for {effective_datetime}")

    try:
        gamma_chart = plot_gamma(df_heatmap=df_gamma, minima_df=minima_df, maxima_df=maxima_df,
                                 effective_datetime=effective_datetime, spx=spx_candlesticks)
        if gamma_chart is None:
            prefect_logger.error("plot_gamma returned None instead of a Plotly figure")
            raise ValueError("Failed to generate gamma chart")

        prefect_logger.info("Successfully created Plotly figure")


        image_width = 1440  # Width in pixels
        image_height = 810  # Height in pixels
        scale_factor = 3  # Increase for better quality, especially for raster formats


        #prefect_logger.info(f"Before update figure size.... layout: {gamma_chart.layout}")
        gamma_chart.update_layout(
            width=image_width,
            height=image_height
        )


        # Try different methods to save the figure
        try:
            img_bytes = gamma_chart.to_image(format="png", scale=scale_factor)
            prefect_logger.info(f"Successfully converted figure to image using to_image. Size: {len(img_bytes)} bytes")
            prefect_logger.info("Sending chart to Discord")
            send_to_discord(DEV_CHANNEL, img_bytes, title=f"Gamma Heatmap for {effective_datetime}")
        except Exception as e:
            prefect_logger.warning(f"to_image failed: {str(e)}. Trying alternative method.")

    except Exception as e:
        prefect_logger.exception(f"Error in plot_and_send_chart: {str(e)}")
        raise


@flow(name="Heatmap Generation Flow")
def heatmap_generation_flow(
    df_book: pd.DataFrame = None,
    steps: float = 2.5,
    range: float = 0.03,
    open_price: float = 5780,
    effective_datetime: str = None,
    effective_date: str = '2024-09-27',
    effective_time: str = '09:00:00'
):
    prefect_logger = get_run_logger()
    #TODO: Effective_date from effective_datetime
    # Input parameters

    spx = {"steps": steps, "range": range}
    open_price = open_price

    #----------------------------------------#
    # Compute heatmap
    start_heatmap_computations = time.time()
    args = argparse.Namespace(proc=os.cpu_count(), mode='delta')

    datetime_object = pd.to_datetime(effective_datetime)


    df_charm, df_gamma, minima_df, maxima_df = compute_heatmap(
        args, type='delta', df_book=df_book,
        start_time=datetime_object, price=open_price,
        steps=spx['steps'], range=spx['range']
    )
    prefect_logger.info(f'It took {time.time() - start_heatmap_computations} to generate the heatmap')

    prefect_logger.info(f"{effective_datetime} heatmap has been processed and plotted.")

    # Gamma
    gamma_to_push = build_unpivot(df_gamma,effective_datetime, minima_df,maxima_df)
    prefect_logger.info(f"Built unpivoted Gamma data. Shape: {gamma_to_push.shape}")
    prefect_logger.info(f'{db.get_status()}')
    db.connect()
    prefect_logger.info(f'{db.get_status()}')
    db.insert_progress('intraday','intraday_gamma',gamma_to_push)

    prefect_logger.info("Inserted gamma data into database")

    # Charm

    charm_to_push = build_unpivot(df_charm,effective_datetime, minima_df,maxima_df)
    prefect_logger.info(f"Built unpivoted Charm data. Shape: {charm_to_push.shape}")
    prefect_logger.info(f'{db.get_status()}')
    db.connect()
    prefect_logger.info(f'{db.get_status()}')
    db.insert_progress('intraday','intraday_charm',charm_to_push)
    stage_pg_data.insert_progress('public', 'charts_intradaygamma', gamma_to_push)
    stage_pg_data.insert_progress('public', 'charts_intradaycharm', charm_to_push)
    prefect_logger.info("Inserted Charm data into database")

if __name__ == "__main__":
    heatmap_generation_flow()
